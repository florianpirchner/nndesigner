package nndesigner

class Design {
	contains Element[*] elements
}

interface Element {
}

interface InputSource {
}

abstract class Layer extends Element, InputSource {
	refers InputSource inputSource
	refers Layer[*] targetLayers
}

abstract class Function extends Element {
}

class KerasDenseLayer extends Layer {
	// dimension of output space
	int numberOfOutputUnits
	/*
	 * nD tensor with shape: (batch_size, ..., input_dim). 
	 * The most common situation would be a 2D input with shape (batch_size, input_dim)
	 */
	int[*] inputShape
	boolean useBias
	/*
	 * Activation function to use (see <a href="https://keras.io/activations/">activations</a>). <br>
	 * If you don't specify anything, no activation is applied (ie. "linear" activation: a(x) = x).
	 */
	refers ActivationFunction activationFunction
	/*
	 * Initializer for the kernel weights matrix (see <a href="https://keras.io/initializers/">initializers</a>).
	 */
	refers InitializerFunction weightsInitializer
	/*
	 *  Initializer for the bias vector (see <a href="https://keras.io/initializers/">initializers</a>).
	 */
	refers InitializerFunction biasInitializer
}

/*
 * Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, 
 * which helps prevent overfitting.
 */
class KerasDropout extends Layer {
	// float between 0 and 1. Fraction of the input units to drop.
	float rate
	/*
	 * 1D integer tensor representing the shape of the binary dropout mask that will be multiplied with the input. <br>
	 * For instance, if your inputs have shape  (batch_size, timesteps, features) and you want the dropout mask to be 
	 * the same for all timesteps, you can use noise_shape=(batch_size, 1, features).
	 */
	int[*] noiseShape
	// A Python integer to use as random seed.
	int seed
}

/*
 * Reshapes an output to a certain shape.<br>
 * <code>
 * 	# as first layer in a Sequential model<br>
 * 		model = Sequential()<br>
 * 		model.add(Reshape((3, 4), input_shape=(12,)))<br>
 * # now: model.output_shape == (None, 3, 4)<br>
 * # note: `None` is the batch dimension<br>
 * <br>
 * # as intermediate layer in a Sequential model<br>
 * 		model.add(Reshape((6, 2)))<br>
 * # now: model.output_shape == (None, 6, 2)<br>
 * <br>
 * # also supports shape inference using `-1` as dimension<br>
 * 		model.add(Reshape((-1, 2, 2)))<br>
 * # now: model.output_shape == (None, 3, 2, 2)<br>
 * </code>
 */
class KerasReshape extends Layer {
	/*
	 * Arbitrary, although all dimensions in the input shaped must be fixed. <br>
	 * Use the keyword argument input_shape (tuple of integers, does not include the batch axis) when using this layer as the 
	 * first layer in a model.
	 */
	int[*] inputShape
	/*
	 * Tuple of integers. Does not include the batch axis.<br>
	 * <code>(batch_size,) + target_shape</code>
	 */
	int[*] outputShape
}

//class KerasInputLayer extends Layer {
//	int inputShapeWidth
//	int inputShapeHeight
//	int batchSize
//	int strideWidth
//	int strideHeight
//	Padding padding
//	refers ActivationFunction activationFunction
//}
//
//class KerasConv2dLayer extends Layer {
//	int filters
//	int kernelWidth
//	int kernelHeight
//	int strideWidth
//	int strideHeight
//	Padding padding
//	refers ActivationFunction activationFunction
//}

//class KerasMaxPool2dLayer extends Layer {
//	int filters
//	int poolSizeHorizontal
//	int poolSizeVertical
//	int strideWidth
//	int strideHeight
//	Padding padding
//}

enum Padding {
	valid = 0
	, same = 1
}

abstract class ActivationFunction extends Function {
}

abstract class LossFunction extends Function {
}

abstract class InitializerFunction extends Element {
}

abstract class MathFunction extends Function {
}

class MatmulFunction extends MathFunction {
}

class DotFunction extends MathFunction {
} 